# âš¡ Instructions Rapides - DÃ¨s que Docker est prÃªt

## âœ… VÃ©rifier que Docker a terminÃ©

Dans Docker Desktop, vous devriez voir :
- âœ… Image `confluentinc/cp-zookeeper:7.4.0` tÃ©lÃ©chargÃ©e
- âœ… Image `confluentinc/cp-kafka:7.4.0` tÃ©lÃ©chargÃ©e

Ou dans le terminal :
```bash
docker-compose ps
```

Vous devriez voir :
```
NAME        STATUS
zookeeper   Up
kafka       Up
```

## ğŸ“‹ Ã‰TAPES Ã€ SUIVRE (dans l'ordre)

### Ã‰TAPE 1 : CrÃ©er le topic Kafka (2 minutes)

```bash
cd d:\bigdata\projetbigdata

docker exec -it kafka bash

# Une fois dans le conteneur Kafka :
kafka-topics --create --topic home_sensors --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# VÃ©rifier que le topic est crÃ©Ã© :
kafka-topics --list --bootstrap-server localhost:9092

# Sortir du conteneur :
exit
```

**âœ… RÃ©sultat attendu :** Vous voyez `home_sensors` dans la liste

---

### Ã‰TAPE 2 : Lancer le producteur (Terminal 1)

```bash
cd d:\bigdata\projetbigdata
venv\Scripts\activate
python producer/sensor_producer.py
```

**âœ… RÃ©sultat attendu :**
```
ğŸš€ Producteur dÃ©marrÃ©. Envoi vers Kafka (localhost:9092)...
ğŸ“ Topic : home_sensors

[1] ğŸ“¤ Ã‰vÃ©nement envoyÃ© : living_room - temperature = 22.5
[2] ğŸ“¤ Ã‰vÃ©nement envoyÃ© : bedroom - humidity = 55.0
[3] ğŸ“¤ Ã‰vÃ©nement envoyÃ© : kitchen - presence = 1
...
```

**âš ï¸ IMPORTANT :** Laisser tourner ce terminal !

---

### Ã‰TAPE 3 : Lancer Spark (Terminal 2 - NOUVEAU)

Ouvrir un **NOUVEAU terminal** :

```bash
cd d:\bigdata\projetbigdata
venv\Scripts\activate
python spark/spark_streaming_analysis.py
```

**âœ… RÃ©sultat attendu :**
```
âœ… Spark Session crÃ©Ã©e
ğŸ“– Connexion Kafka Ã©tablie
ğŸ” SchÃ©ma parsÃ© :
root
 |-- room: string
 |-- sensor_type: string
 |-- value: double
 |-- timestamp: string
 |-- device_id: string

âœ… Spark Streaming dÃ©marrÃ©. Appuyez sur Ctrl+C pour arrÃªter.

+-------------------+-------------------+-----------+-----------+---------+---------+---------+-----+
|window_start       |window_end         |room       |sensor_type|avg_value|min_value|max_value|count|
+-------------------+-------------------+-----------+-----------+---------+---------+---------+-----+
|2025-12-16 15:00:00|2025-12-16 15:01:00|living_room|temperature|22.7     |21.5     |24.1     |15   |
+-------------------+-------------------+-----------+-----------+---------+---------+---------+-----+
```

**ğŸ‰ SI VOUS VOYEZ Ã‡A : LE PROJET FONCTIONNE !**

---

### Ã‰TAPE 4 : Prendre les screenshots

1. **Terminal producteur** â†’ Capture d'Ã©cran
2. **Terminal Spark** â†’ Capture d'Ã©cran (avec les tableaux)
3. **Docker Desktop** â†’ Onglet "Containers" montrant kafka et zookeeper "Running"
4. **Explorateur** â†’ `data/output/` avec les fichiers gÃ©nÃ©rÃ©s

Sauvegarder dans `screenshots/`

---

### Ã‰TAPE 5 : ArrÃªter proprement

```bash
# Terminal producteur : Ctrl+C
# Terminal Spark : Ctrl+C

# ArrÃªter Docker :
docker-compose down
```

---

## ğŸ› ProblÃ¨mes courants

### "kafka: command not found"
â†’ Vous n'Ãªtes pas dans le conteneur. Relancer `docker exec -it kafka bash`

### "Connection refused to localhost:9092"
â†’ Kafka n'est pas encore prÃªt. Attendre 15-20 secondes aprÃ¨s `docker-compose up`

### "No module named kafka"
â†’ Activer le venv : `venv\Scripts\activate`

### Le producteur s'arrÃªte immÃ©diatement
â†’ VÃ©rifier que Kafka tourne : `docker-compose ps`

---

## â±ï¸ TEMPS TOTAL ESTIMÃ‰

- âœ… Docker terminÃ© : DÃ‰JÃ€ FAIT
- â±ï¸ CrÃ©er topic : 2 minutes
- â±ï¸ Tester producteur : 1 minute
- â±ï¸ Tester Spark : 2 minutes
- â±ï¸ Screenshots : 5 minutes
- â±ï¸ Git push : 2 minutes

**TOTAL : ~15 minutes une fois Docker prÃªt !**

